{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc92d39-dbce-4079-b943-884deb2373c6",
   "metadata": {},
   "source": [
    "# Leverage deployment guardrails to update a HuggangFace SageMaker Inference endpoint using canary traffic shifting\n",
    "\n",
    "This notebook is developed based on the [SageMaker github examples](https://github.com/aws/amazon-sagemaker-examples/tree/main/sagemaker-inference-deployment-guardrails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab1685-af71-48b3-b008-1e18fa71b2ed",
   "metadata": {},
   "source": [
    "# Introduction <a id='Introduction'></a>\n",
    "\n",
    "Deployment guardrails are a set of model deployment options in Amazon SageMaker Inference to update your machine learning models in production. Using the fully managed deployment guardrails, you can control the switch from the current model in production to a new one. Traffic shifting modes, such as canary and linear, give you granular control over the traffic shifting process from your current model to the new one during the course of the update. There are also built-in safeguards such as auto-rollbacks that help you catch issues early and take corrective action before they impact production.\n",
    "\n",
    "We support blue-green deployment with multiple traffic shifting modes. A traffic shifting mode is a configuration that specifies how endpoint traffic is routed to a new fleet containing your updates. The following traffic shifting modes provide you with different levels of control over the endpoint update process:\n",
    "\n",
    "* **All-At-Once Traffic Shifting** : shifts all of your endpoint traffic from the blue fleet to the green fleet. Once the traffic has shifted to the green fleet, your pre-specified Amazon CloudWatch alarms begin monitoring the green fleet for a set amount of time (the “baking period”). If no alarms are triggered during the baking period, then the blue fleet is terminated.\n",
    "* **Canary Traffic Shifting** : lets you shift one small portion of your traffic (a “canary”) to the green fleet and monitor it for a baking period. If the canary succeeds on the green fleet, then the rest of the traffic is shifted from the blue fleet to the green fleet before terminating the blue fleet.\n",
    "* **Linear Traffic Shifting** : provides even more customization over how many traffic-shifting steps to make and what percentage of traffic to shift for each step. While canary shifting lets you shift traffic in two steps, linear shifting extends this to n number of linearly spaced steps.\n",
    "\n",
    "\n",
    "The Deployment guardrails for Amazon SageMaker Inference endpoints feature also allows customers to specify conditions/alarms based on Endpoint invocation metrics from CloudWatch to detect model performance regressions and trigger automatic rollback.\n",
    "\n",
    "In this notebook we'll update endpoint with following deployment configurations:\n",
    " * Blue/Green update policy with **Canary traffic shifting option**\n",
    " * Configure CloudWatch alarms to monitor model performance and trigger auto-rollback action.\n",
    "  \n",
    "To demonstrate Canary deployments and the auto-rollback feature, we will update an Endpoint with an incompatible model version and deploy it as a Canary fleet, taking a small percentage of the traffic. Requests sent to this Canary fleet will result in errors, which will be used to trigger a rollback using pre-specified CloudWatch alarms. Finally, we will also demonstrate a success scenario where no alarms are tripped and the update succeeds. \n",
    "\n",
    "This notebook is organized in 4 steps -\n",
    "* Step 1 creates the models and Endpoint Configurations required for the 3 scenarios - the baseline, the update containing the incompatible model version and the update containing the correct model version. \n",
    "* Step 2 invokes the baseline Endpoint prior to the update. \n",
    "* Step 3 specifies the CloudWatch alarms used to trigger the rollbacks. \n",
    "* Finally in step 4, we update the endpoint to trigger a rollback and demonstrate a successful update. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9c6fb-9995-41a8-ae56-440d4f1f3667",
   "metadata": {},
   "source": [
    "# Setup <a id='Setup'></a>\n",
    "\n",
    "Ensure that you have an updated version of boto3, which includes the latest SageMaker features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00d135-52d6-4347-bc60-5209bee52a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# You can use a different IAM role with \"SageMakerFullAccess\" policy for this notebook\n",
    "role = get_execution_role()\n",
    "print(f\"Execution role: {role}\")\n",
    "\n",
    "sm_session = session.Session(boto3.Session())\n",
    "sm_client = boto3.Session().client(\"sagemaker\")\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "\n",
    "# You can use a different bucket, but make sure the role you chose for this notebook\n",
    "# has the s3:PutObject permissions. This is the bucket into which the model artifacts will be uploaded\n",
    "bucket = sm_session.default_bucket()\n",
    "prefix = \"sagemaker/huggingface-pytorch-sentiment-analysis\"\n",
    "\n",
    "time_now = f'{datetime.datetime.now():%Y-%m-%d-%H-%M-%S}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45337c2c-18c8-49b9-af81-8be00008219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cefe16-18f2-402e-978d-2b08fa1bafce",
   "metadata": {},
   "source": [
    "# Step 1: Deploy the models created in the previous notebooks<a id='Step1'></a>\n",
    "\n",
    "### First, we create endpoint configurations based on the previously created models \n",
    "\n",
    "\n",
    "The models in this example are used to analyse the sentiment of a given sentence. The dataset we use is based on a subset of a Kaggle dataset available [here](https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis). \n",
    "\n",
    "We now create three EndpointConfigs, corresponding to the three Models we created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e5d8d-cfdd-4d28-b7d0-23b81774566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_config_name_roberta = ep_config_name\n",
    "ep_config_name_distilbert = ep_config_name2\n",
    "ep_config_name_roberta_mme = ep_config_name3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21964a-04e7-47d2-9fcb-79598e58a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ep_config_name_roberta = f\"hf-EpConfig-roberta-{time_now}\"\n",
    "ep_config_name_distilbert = f\"hf-EpConfig-distilbert-{time_now}\"\n",
    "ep_config_name_roberta_mme = f\"hf-EpConfig-roberta-mme-{time_now}\"\n",
    "\n",
    "print(f\"Endpoint Config 1: {ep_config_name_roberta}\")\n",
    "print(f\"Endpoint Config 2: {ep_config_name_distilbert}\")\n",
    "print(f\"Endpoint Config 3: {ep_config_name_roberta_mme}\")\n",
    "\n",
    "resp = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=ep_config_name_roberta,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ModelName\": roberta_model_name,\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialInstanceCount\": 3,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"Created Endpoint Config: {resp}\")\n",
    "time.sleep(5)\n",
    "\n",
    "resp = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=ep_config_name_distilbert,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ModelName\": distilbert_model_name,\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialInstanceCount\": 3,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"Created Endpoint Config: {resp}\")\n",
    "time.sleep(5)\n",
    "\n",
    "resp = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=ep_config_name_roberta_mme,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "            \"ModelName\": roberta_mme_model_name,\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialInstanceCount\": 3,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(f\"Created Endpoint Config: {resp}\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef68aa9-dd5e-472f-baf3-d0d8ae64ad96",
   "metadata": {},
   "source": [
    "### Create Endpoint\n",
    "\n",
    "Deploy the roberta model to a new SageMaker endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7d903-2ae5-4817-b76c-7a7f9c5556aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"hf-deployment-guardrails-canary-{time_now}\"\n",
    "print(f\"Endpoint Name: {endpoint_name}\")\n",
    "\n",
    "resp = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=ep_config_name_roberta_mme)\n",
    "print(f\"\\nCreated Endpoint: {resp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff4509-50ae-4c8d-a1dc-1f536d1dda8a",
   "metadata": {},
   "source": [
    "Wait for the endpoint creation to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b7019-1e2c-465f-82b6-ee6b67816075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_endpoint_in_service(endpoint_name):\n",
    "    print(\"Waiting for endpoint in service\")\n",
    "    while True:\n",
    "        details = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = details[\"EndpointStatus\"]\n",
    "        if status in [\"InService\", \"Failed\"]:\n",
    "            print(\"\\nDone!\")\n",
    "            break\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "wait_for_endpoint_in_service(endpoint_name)\n",
    "\n",
    "sm_client.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2486-aaaa-420d-9d13-bfc166a0de1e",
   "metadata": {},
   "source": [
    "# Step 2: Invoke Endpoint <a id='Step2'></a>\n",
    "\n",
    "You can now send data to this endpoint to get inferences in real time.\n",
    "\n",
    "This step invokes the endpoint with included sample data with maximum invocations count and waiting intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef634f-bbb0-4fb6-94e1-6d033d241853",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d14b8b-aad7-4511-912f-9022eafae99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(\n",
    "    endpoint_name, max_invocations=100, wait_interval_sec=1, should_raise_exp=False\n",
    "):\n",
    "    print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "    nm_rounds = round(max_invocations/100)\n",
    "    count = 0\n",
    "    for i in range(nm_rounds):\n",
    "        with open(\"../sample_payload/batch_data.csv\", \"r\") as f:\n",
    "            for row in f:\n",
    "                payload = row.rstrip(\"\\n\")\n",
    "                try:\n",
    "                    response = sm_runtime.invoke_endpoint(\n",
    "                        EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    "                    )\n",
    "                    response[\"Body\"].read()\n",
    "                    print(\".\", end=\"\", flush=True)\n",
    "                except Exception as e:\n",
    "                    print(\"E\", end=\"\", flush=True)\n",
    "                    if should_raise_exp:\n",
    "                        raise e\n",
    "                count += 1\n",
    "                if count > max_invocations:\n",
    "                    break\n",
    "                time.sleep(wait_interval_sec)\n",
    "\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "invoke_endpoint(endpoint_name, max_invocations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b88aca-2407-495e-9ace-a91a602d95b3",
   "metadata": {},
   "source": [
    "### Invocations Metrics\n",
    "\n",
    "Amazon SageMaker emits metrics such as Latency and Invocations per variant/Endpoint Config (full list of metrics [here](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html)) in Amazon CloudWatch.\n",
    "\n",
    "Query CloudWatch to get number of Invocations and latency metrics per variant and endpoint configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88de50c-8e8b-4c1d-ac6e-0f75cb74420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = boto3.Session().client(\"cloudwatch\", region_name=region)\n",
    "\n",
    "\n",
    "def get_sagemaker_metrics(\n",
    "    endpoint_name,\n",
    "    endpoint_config_name,\n",
    "    variant_name,\n",
    "    metric_name,\n",
    "    statistic,\n",
    "    start_time,\n",
    "    end_time,\n",
    "):\n",
    "    dimensions = [\n",
    "        {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "        {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "    ]\n",
    "    if endpoint_config_name is not None:\n",
    "        dimensions.append({\"Name\": \"EndpointConfigName\", \"Value\": endpoint_config_name})\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=metric_name,\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[statistic],\n",
    "        Dimensions=dimensions,\n",
    "    )\n",
    "    rename = endpoint_config_name if endpoint_config_name is not None else \"ALL\"\n",
    "    if len(metrics[\"Datapoints\"]) == 0:\n",
    "        return\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop([\"Unit\"], axis=1)\n",
    "        .rename(columns={statistic: rename})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_invocation_metrics(\n",
    "    endpoint_name,\n",
    "    endpoint_config_name,\n",
    "    variant_name,\n",
    "    metric_name,\n",
    "    statistic,\n",
    "    start_time=None,\n",
    "):\n",
    "    start_time = start_time or datetime.datetime.now(datetime.timezone.utc) - timedelta(minutes=60)\n",
    "    end_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    metrics_variants = get_sagemaker_metrics(\n",
    "        endpoint_name,\n",
    "        endpoint_config_name,\n",
    "        variant_name,\n",
    "        metric_name,\n",
    "        statistic,\n",
    "        start_time,\n",
    "        end_time,\n",
    "    )\n",
    "    if metrics_variants is None:\n",
    "        return\n",
    "    metrics_variants.plot(title=f\"{metric_name}-{statistic}\")\n",
    "    return metrics_variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c9bf3-e6e2-44a2-be0b-e9076846c015",
   "metadata": {},
   "source": [
    "### Plot endpoint invocation metrics:\n",
    "\n",
    "Below, we are going to plot graphs to show the Invocations,Invocation4XXErrors,Invocation5XXErrors,ModelLatency and OverheadLatency against the Endpoint.\n",
    "\n",
    "You will observe that there should be a flat line for Invocation4XXErrors and Invocation5XXErrors as we are using the correct invocation data, model and configs. Additionally, ModelLatency and OverheadLatency will start decreasing over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7adacc6-1b61-4f26-88f0-9630aaa47869",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_name, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "invocation_4xx_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocation4XXErrors\", \"Sum\"\n",
    ")\n",
    "invocation_5xx_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocation5XXErrors\", \"Sum\"\n",
    ")\n",
    "model_latency_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"ModelLatency\", \"Average\"\n",
    ")\n",
    "overhead_latency_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"OverheadLatency\", \"Average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cd68-3216-4148-8857-95f8a8c0e87d",
   "metadata": {},
   "source": [
    "# Step 3: Create CloudWatch alarms to monitor Endpoint performance <a id='Step3'></a>\n",
    "\n",
    "Create CloudWatch alarms to monitor Endpoint performance with following metrics:\n",
    "* Invocation5XXErrors\n",
    "* ModelLatency\n",
    "\n",
    "Following metric dimensions are used to select the metric per Endpoint config and variant:\n",
    "* EndpointName\n",
    "* VariantName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdf617-1de7-44e3-bd1c-1c9cc6bcf613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_auto_rollback_alarm(\n",
    "    alarm_name, endpoint_name, variant_name, metric_name, statistic, threshold\n",
    "):\n",
    "    cw.put_metric_alarm(\n",
    "        AlarmName=alarm_name,\n",
    "        AlarmDescription=\"Test SageMaker endpoint deployment auto-rollback alarm\",\n",
    "        ActionsEnabled=False,\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=metric_name,\n",
    "        Statistic=statistic,\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "        Period=60,\n",
    "        EvaluationPeriods=1,\n",
    "        Threshold=threshold,\n",
    "        ComparisonOperator=\"GreaterThanOrEqualToThreshold\",\n",
    "        TreatMissingData=\"notBreaching\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d6703-c852-425e-abba-b5560801cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_alarm = f\"TestAlarm-4XXErrors-{endpoint_name}\"\n",
    "latency_alarm = f\"TestAlarm-ModelLatency-{endpoint_name}\"\n",
    "\n",
    "# alarm on 1% 4xx error rate for 1 minute\n",
    "create_auto_rollback_alarm(\n",
    "    error_alarm, endpoint_name, \"AllTraffic\", \"Invocation4XXErrors\", \"Sum\", 1\n",
    ")\n",
    "# alarm on model latency >= 200 ms for 1 minute\n",
    "create_auto_rollback_alarm(\n",
    "    latency_alarm, endpoint_name, \"AllTraffic\", \"ModelLatency\", \"Average\", 200000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a865e69-f5c0-424c-936e-8133c034f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.describe_alarms(AlarmNames=[error_alarm, latency_alarm])\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc182f-b3c0-4ece-ad8c-e9693f037129",
   "metadata": {},
   "source": [
    "# Step 4: Update Endpoint with deployment configurations <a id='Step4'></a>\n",
    "\n",
    "Update the endpoint with deployment configurations and monitor the performance from CloudWatch metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba641a7-5b7d-4919-a750-a486c525ffe8",
   "metadata": {},
   "source": [
    "### BlueGreen update policy with Canary traffic shifting\n",
    "\n",
    "We define the following deployment configuration to perform Blue/Green update strategy with Canary traffic shifting from old to new stack. The Canary traffic shifting option can reduce the blast ratio of a regressive update to the endpoint. In contrast, for the All-At-Once traffic shifting option, the invocation requests start failing at 100% after flipping the traffic. In the Canary mode, invocation requests are shifted to the new version of model gradually, preventing errors from impacting 100% of your traffic. Additionally, the auto-rollback alarms monitor the metrics during the canary stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defdcdba-5bae-4686-8df0-051db223e44a",
   "metadata": {},
   "source": [
    "### Rollback Case \n",
    "![Rollback case](images/scenario-canary-rollback.png)\n",
    "\n",
    "Update the Endpoint with an incompatible model version with the test data format to simulate errors and trigger a rollback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8ca5b-9b31-49f2-8480-112dd5442f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "canary_deployment_config = {\n",
    "    \"BlueGreenUpdatePolicy\": {\n",
    "        \"TrafficRoutingConfiguration\": {\n",
    "            \"Type\": \"CANARY\",\n",
    "            \"CanarySize\": {\n",
    "                \"Type\": \"INSTANCE_COUNT\",  # or use \"CAPACITY_PERCENT\" as 30%, 50%\n",
    "                \"Value\": 1,\n",
    "            },\n",
    "            \"WaitIntervalInSeconds\": 300,  # wait for 5 minutes before enabling traffic on the rest of fleet\n",
    "        },\n",
    "        \"TerminationWaitInSeconds\": 120,  # wait for 2 minutes before terminating the old stack\n",
    "        \"MaximumExecutionTimeoutInSeconds\": 1800,  # maximum timeout for deployment\n",
    "    },\n",
    "    \"AutoRollbackConfiguration\": {\n",
    "        \"Alarms\": [{\"AlarmName\": error_alarm}, {\"AlarmName\": latency_alarm}],\n",
    "    },\n",
    "}\n",
    "\n",
    "# update endpoint request with new DeploymentConfig parameter\n",
    "sm_client.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=ep_config_name_roberta,\n",
    "    DeploymentConfig=canary_deployment_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19a359-63f0-47dc-87ec-7c90ccdbe284",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34731f-a933-4b1e-82e8-043689095e1a",
   "metadata": {},
   "source": [
    "### We invoke the endpoint during the update operation is in progress.\n",
    "\n",
    "**Note : Invoke endpoint in this notebook is in single thread mode, to stop the invoke requests please stop the cell execution**\n",
    "\n",
    "The E's denote the errors generated from the incompatible model version in the canary fleet.\n",
    "\n",
    "The purpose of the below cell is to simulate errors in the canary fleet. Since the nature of traffic shifting to the canary fleet is probabilistic, you should wait until you start seeing errors. Then, you may proceed to stop the execution of the below cell. If not aborted, cell will run for 100 invocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44020f-4e1b-4bd8-9165-95c6f28da254",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint(endpoint_name, max_invocations=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9005e7-823d-4e2e-bae7-efcf908c6196",
   "metadata": {},
   "source": [
    "Wait for the update operation to complete and verify the automatic rollback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355c2b4-a071-4b78-b1d7-4f47682fa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_endpoint_in_service(endpoint_name)\n",
    "\n",
    "sm_client.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e8345-4ece-42d9-a6af-3f591477769f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cw.describe_alarm_history(AlarmName=error_alarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b705d7-c3d7-4d67-8e60-8610b9f201f0",
   "metadata": {},
   "source": [
    "Collect the endpoint metrics during the deployment:\n",
    "\n",
    "Below, we are going to plot graphs to show the Invocations,Invocation4XXErrors and ModelLatency against the Endpoint.\n",
    "\n",
    "You can expect to see as the new endpoint config-2 (erroneous due to model version) starts getting deployed, it encounters failure and leads to the rollback to endpoint config-1. This can be seen in the graphs below as the Invocation4XXErrors and ModelLatency increases during this rollback phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f9682-ba76-4ce6-ade3-f7b9af87b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "metrics_epc_3 = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_name3, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "metrics_epc_1 = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_name, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "\n",
    "metrics_all = invocation_metrics.join([metrics_epc_3, metrics_epc_1], how=\"outer\")\n",
    "metrics_all.plot(title=\"Invocations-Sum\")\n",
    "\n",
    "invocation_5xx_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocation4XXErrors\", \"Sum\"\n",
    ")\n",
    "model_latency_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"ModelLatency\", \"Average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84debb-44db-4155-95b1-143c52091b0c",
   "metadata": {},
   "source": [
    "Let's take a look at the Success case where we use the same Canary deployment configuration but a valid endpoint configuration.\n",
    "\n",
    "### Success Case\n",
    "![Success case](images/scenario-canary-success.png)\n",
    "\n",
    "Now we show the success case where the Endpoint Configuration is updated to a valid version (using the same Canary deployment config as the rollback case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4276b-a375-483a-9b3a-9a74e7613003",
   "metadata": {},
   "source": [
    "Update the endpoint with the same Canary deployment configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b20e6b-91a1-4530-ba00-e351234f6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update endpoint with a valid version of DeploymentConfig\n",
    "\n",
    "sm_client.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=ep_config_name_distilbert,\n",
    "    RetainDeploymentConfig=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce951ff-ee21-4424-9957-dea57a77bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0801475-52c9-4506-b41b-74081c9e6db6",
   "metadata": {},
   "source": [
    "Invoke the endpoint during the update operation is in progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f93416-3a86-4790-a676-2fb62a41d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint(endpoint_name, max_invocations=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea89f61f-d328-4141-a2aa-e9899ea8a818",
   "metadata": {},
   "source": [
    "wait for the update operation to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2589cb8-96e4-4e1e-9afe-6527a0f43a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_endpoint_in_service(endpoint_name)\n",
    "\n",
    "sm_client.describe_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed42ee-46ba-4889-9fea-0865adb9c0bf",
   "metadata": {},
   "source": [
    "Collect the endpoint metrics during the deployment:\n",
    "\n",
    "Below, we are going to plot graphs to show the Invocations,Invocation5XXErrors and ModelLatency against the Endpoint.\n",
    "\n",
    "You can expect to see that, as the new endpoint config-3 (correct model version) starts getting deployed, it takes over endpoint config-2 (incompatible due to model version) without any errors. This can be seen in the graphs below as the Invocation5XXErrors and ModelLatency decreases during this transition phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3841ec-ff77-40ea-a9bc-6e5386972f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "metrics_epc_1 = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_name_roberta, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "metrics_epc_2 = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_distilbert, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "metrics_epc_3 = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, ep_config_roberta_mme, \"AllTraffic\", \"Invocations\", \"Sum\"\n",
    ")\n",
    "\n",
    "metrics_all = invocation_metrics.join([metrics_epc_1, metrics_epc_2, metrics_epc_3], how=\"outer\")\n",
    "metrics_all.plot(title=\"Invocations-Sum\")\n",
    "\n",
    "invocation_4xx_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"Invocation4XXErrors\", \"Sum\"\n",
    ")\n",
    "model_latency_metrics = plot_endpoint_invocation_metrics(\n",
    "    endpoint_name, None, \"AllTraffic\", \"ModelLatency\", \"Average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51215819-cf9a-402e-8946-1fe4f822e589",
   "metadata": {},
   "source": [
    "The Amazon CloudWatch metrics for the total invocations for each endpoint config shows how invocation requests are shifted from the old version to the new version during deployment.\n",
    "\n",
    "You can now safely update your endpoint and monitor model regressions during deployment and trigger auto-rollback action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd60f9-5b7a-434c-a0dd-f321acde2c2e",
   "metadata": {},
   "source": [
    "# Cleanup <a id='Cleanup'></a>\n",
    "\n",
    "If you do not plan to use this endpoint further, you should delete the endpoint to avoid incurring additional charges and clean up other resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575a77e-f9b8-4017-94e5-8e1c3b277956",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbfa8a-4bdb-42ed-bb58-02cd9b59c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint_config(EndpointConfigName=ep_config_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=ep_config_name2)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=ep_config_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f554b3-7e48-44c9-a994-87cbc0d5a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw.delete_alarms(AlarmNames=[error_alarm, latency_alarm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810b675-9005-4ba5-befa-33f036be1996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
