{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c00f4b5-2e2a-4001-a75b-db900a180f3b",
   "metadata": {},
   "source": [
    "# Deploy Hugging Face transformer models with multi-model endpoints \n",
    "\n",
    "This notebook is a step-by-step tutorial on deploying multiple pre-trained PyTorch Hugging Face model with multi-model endpoint on Amazon SageMaker. \n",
    "\n",
    "We will describe the steps for deploying a multi-model endpoint on Amazon SageMaker with TorchServe serving stack. An additional step compared to single model deployment is the requirement to create a manifest file for each model prior to deployment. For training Hugging Face models on SageMaker, refer the examples [here](https://github.com/huggingface/notebooks/tree/master/sagemaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1092eb5-7116-4619-8e78-7e9833f285b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import boto3\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import shutil \n",
    "import datetime\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sm_session = sagemaker.Session()\n",
    "bucket = sm_session.default_bucket()\n",
    "sm_client = boto3.client(\"sagemaker\", region)\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "s3_client = boto3.client('s3')\n",
    "prefix = \"sagemaker/huggingface-pytorch-sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b211b-2aee-45f7-ae96-12c2ff2fbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd6cc57-49aa-40c7-bdd2-9def40e7bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    describe_model_package_group_response = sm_client.describe_model_package_group(\n",
    "        ModelPackageGroupName=model_package_group_name\n",
    "    )\n",
    "    print(describe_model_package_group_response)\n",
    "except:\n",
    "    print(f\"model package group {model_package_group_name} does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5743d3-1f1a-457b-80fb-f758607d7b9c",
   "metadata": {},
   "source": [
    "### Register a new model version for Hugging Face roberta model with entry point script helper function\n",
    "we will firstly download the roberta model file and prepare the model with inference script to be used in the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788dfd4-e349-4a21-a521-0d225db9bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_artifact_path = Path(\"model_artifacts\")\n",
    "local_artifact_path.mkdir(exist_ok=True, parents=True)\n",
    "model_tar_name = 'model_roberta_MME.tar.gz'\n",
    "org_model_tar_name = model_roberta_uri.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899d5fe-424d-4371-812e-5fd7d32c3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(bucket, '/'.join(model_roberta_uri.split('/')[3:]), org_model_tar_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aeb060-bcff-4b9c-aaa1-c3371c162598",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(org_model_tar_name) as tar:\n",
    "    tar.extractall(path=local_artifact_path.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20228089-bbb5-49a6-b11e-8e70598f4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree('../code', local_artifact_path / 'code') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2915503-2457-49c6-a962-250d087241fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tar(tarfile_name: str, local_path: Path):\n",
    "    \"\"\"\n",
    "    Create a tar.gz archive with the content of `local_path`.\n",
    "    \"\"\"\n",
    "    with tarfile.open(tarfile_name, mode=\"w:gz\") as archive:\n",
    "        [\n",
    "            archive.add(k, arcname=f\"{k.relative_to(local_path)}\")\n",
    "            for k in local_path.glob(\"**/*.*\")\n",
    "            if f\"{k.relative_to(local_path)}\"[0] != \".\"\n",
    "        ]\n",
    "    tar_size = Path(tarfile_name).stat().st_size / 10**6\n",
    "    return tar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068f177-e38f-4a33-9bf2-5620d51908a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_size = create_tar(model_tar_name, local_artifact_path)\n",
    "print(f\"Created {model_tar_name}, size {tar_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb6ab6-fd6f-4f00-be22-6a1dfa1b7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "model_data_path = s3_path_join(\"s3://\",bucket,prefix+\"/models\")\n",
    "model_roberta_mme_uri =S3Uploader.upload(model_tar_name, model_data_path)\n",
    "print(f\"Uploaded roberta model to {model_roberta_mme_uri}\")\n",
    "%store model_roberta_mme_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb72cb-f5f9-4b4e-81bc-ae5c9120a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_packages_response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name\n",
    ")\n",
    "list_model_packages_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44495d63-7bc3-4576-87d7-ff285c2b417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_model_package_response = sm_client.describe_model_package(\n",
    "    ModelPackageName=roberta_model_package_arn\n",
    ")\n",
    "describe_model_package_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0063f-791c-40d2-8580-53b0eaa10464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_response = sm_client.create_model_package(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageDescription=f\"Hugging Face Roberta Model MME - sentiment analysis\",\n",
    "    Domain=describe_model_package_response['Domain'],\n",
    "    Task=describe_model_package_response['Task'],\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [\n",
    "            {\n",
    "                \"ContainerHostname\": \"huggingface-pytorch-roberta-update\",\n",
    "                \"Image\": describe_model_package_response['InferenceSpecification']['Containers'][0]['Image'],\n",
    "                \"ModelDataUrl\": model_roberta_mme_uri,\n",
    "                \"Framework\": describe_model_package_response['InferenceSpecification']['Containers'][0]['Framework'],\n",
    "                \"NearestModelName\": describe_model_package_response['InferenceSpecification']['Containers'][0]['NearestModelName'],\n",
    "                \"Environment\": {\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": describe_model_package_response['InferenceSpecification']['Containers'][0]['Environment']['SAGEMAKER_CONTAINER_LOG_LEVEL'],\n",
    "                    \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "                    \"SAGEMAKER_REGION\": region,\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": model_roberta_mme_uri,\n",
    "                    \"HF_TASK\": describe_model_package_response['InferenceSpecification']['Containers'][0]['Environment']['HF_TASK'],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": describe_model_package_response['InferenceSpecification']['SupportedRealtimeInferenceInstanceTypes'],\n",
    "        \"SupportedContentTypes\": [\"application/json\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"application/json\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931c5d2-4cfc-46af-a10a-fa129f6d280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_packages_response = sm_client.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name\n",
    ")\n",
    "list_model_packages_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6b155-6e41-42c2-af56-9e583190e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_mme_model_version_arn = list_model_packages_response[\"ModelPackageSummaryList\"][0][\"ModelPackageArn\"]\n",
    "print(\"roberta MME model: {}\".format(roberta_mme_model_version_arn))\n",
    "distilbert_model_version_arn = list_model_packages_response[\"ModelPackageSummaryList\"][1][\"ModelPackageArn\"]\n",
    "print(\"distilbert model: {}\".format(distilbert_model_version_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e98aa-5d84-4664-97f3-9b5fc22ae49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\": roberta_mme_model_version_arn,\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "model_package_update_response = sm_client.update_model_package(**model_package_update_input_dict)\n",
    "model_package_update_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953ccc3-cbcd-4dd4-93dd-6bb15561b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "now_roberta_mme = f'{datetime.datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "roberta_mme_model_name = f\"hf-pytorch-model-roberta-mme-{now_roberta_mme}\"\n",
    "print(\"Model name : {}\".format(roberta_mme_model_name))\n",
    "%store roberta_mme_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf93201-3f41-49bb-b0e2-3b5d3b9f51a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container_roberta = {\n",
    "    \"ModelPackageName\": roberta_mme_model_version_arn,\n",
    "}\n",
    "\n",
    "create_model_roberta_respose = sm_client.create_model(\n",
    "    ModelName=roberta_mme_model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=primary_container_roberta\n",
    ")\n",
    "%store roberta_mme_model_name\n",
    "print(\"Model arn : {}\".format(create_model_roberta_respose[\"ModelArn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefca41c-27cf-41e2-9cfd-90fd411cff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = describe_model_package_response['InferenceSpecification']['Containers'][0]['Image']\n",
    "image_uri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0549e8b-efad-4c37-bfce-95012ad2af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_instance_type = describe_model_package_response['InferenceSpecification']['SupportedRealtimeInferenceInstanceTypes'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa9505-c6cb-44a9-bead-aeeaf79b6c2f",
   "metadata": {},
   "source": [
    "### Create the model metadata\n",
    "Here we use `boto3` to establish the model metadata. Instead of describing a single model, this metadata will indicate the use of multi-model semantics and will identify the source location of all specific model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bfb5d-4054-4fe0-b00b-dc8032e36599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the place in S3 from which the endpoint will pull individual models\n",
    "multi_model_now = f'{datetime.datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "multi_model_name = f'pytorch-multi-model-senti-{multi_model_now}'\n",
    "_container = {\n",
    "    'Image':        image_uri,\n",
    "    'ModelDataUrl': model_data_path,\n",
    "    'Mode':         'MultiModel'\n",
    "}\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = multi_model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [_container])\n",
    "%store multi_model_name\n",
    "print(f'Multi Model name {multi_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bdb34a-8bd1-4c3b-b0be-3e29038ad971",
   "metadata": {},
   "source": [
    "### Create the multi-model endpoint\n",
    "There is nothing special about the SageMaker endpoint config metadata for a multi-model endpoint. You need to consider the appropriate instance type and number of instances for the projected prediction workload. The number and size of the individual models will drive memory requirements.\n",
    "endpoint_config_name =\n",
    "Once the endpoint config is in place, the endpoint creation is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59e878-247d-4943-97fb-356025d78828",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f'pytorch-multi-model-config-{multi_model_now}'\n",
    "print('Endpoint config name: ' + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': deploy_instance_type,\n",
    "        'InitialInstanceCount': 1,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': multi_model_name,\n",
    "        'VariantName': 'AllTraffic'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b377a55-b8fd-4236-bc55-7cb9aea36295",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f'pytorch-multi-model-endpoint-{multi_model_now}'\n",
    "print('Endpoint name: ' + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0985ac-9fb8-4e0a-864a-efa59242ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(15)\n",
    "\n",
    "describe_endpoint_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3f98d-d804-4c95-afb9-711ebb665bbe",
   "metadata": {},
   "source": [
    "### Invoke multi-model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8584aa-1078-453f-864c-6b0de1677fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../sample_payload/test_data.csv\", header=None)\n",
    "json_data = dict({'inputs':test_data.iloc[:,0].to_list()})\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c901520-a047-4a83-8835-b5b32aadfbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_multi_model_endpoint(model_archive=None, content_type=\"JSON\", test_data=None):\n",
    "\n",
    "    if content_type == \"JSON\":\n",
    "\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(test_data),\n",
    "            ContentType=\"application/json\",\n",
    "            TargetModel=model_archive,\n",
    "        )\n",
    "    elif content_type == \"CSV\":\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=test_data.to_csv(header=False, index=False),\n",
    "            ContentType=\"text/csv\",\n",
    "            TargetModel=model_archive,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"input content type {content_type} is not supported, please selece CSV or JSON.\")\n",
    "    return response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b7145-39da-4f6c-b191-79754e2e3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_archive = '/model_roberta_MME.tar.gz'\n",
    "content_type = \"JSON\" #\"CSV\"\n",
    "payload = json_data #test_data\n",
    "results = invoke_multi_model_endpoint(model_archive, content_type, payload)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0564b95-d5cc-4e49-a594-5788fc012c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_archive = '/model_roberta_MME.tar.gz'\n",
    "content_type = \"CSV\"\n",
    "payload = test_data\n",
    "results = invoke_multi_model_endpoint(model_archive, content_type, payload)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7dd77-d2ef-4fbf-8887-ba47a82bf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_archive = '/model_distilbert.tar.gz'\n",
    "content_type = \"JSON\" #\"CSV\"\n",
    "payload = json_data #test_data\n",
    "results = invoke_multi_model_endpoint(model_archive, content_type, payload)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5363f6-34e3-49fc-84f1-d3ad0a0826e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_archive = '/model_distilbert.tar.gz'\n",
    "content_type = \"CSV\"\n",
    "payload = test_data\n",
    "results = invoke_multi_model_endpoint(model_archive, content_type, payload)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1c964-c2c0-4a98-8489-8b40b4f5f24b",
   "metadata": {},
   "source": [
    "## Delete the endpoint\n",
    "\n",
    "If you do not plan to use this endpoint further, you should delete the endpoint to avoid incurring additional charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973027c4-f298-4f4b-b194-094d107c0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
