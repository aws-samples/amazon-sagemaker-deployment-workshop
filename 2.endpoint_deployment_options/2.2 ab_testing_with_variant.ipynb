{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad718ed6-890f-4a3d-a6c4-9eb29d8f92e7",
   "metadata": {},
   "source": [
    "# A/B Testing with Amazon SageMaker\n",
    "\n",
    "In production ML workflows, data scientists and data engineers frequently try to improve their models in various ways, such as by performing [Perform Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html), training on additional or more-recent data, and improving feature selection. Performing A/B testing between a new model and an old model with production traffic can be an effective final step in the validation process for a new model. In A/B testing, you test different variants of your models and compare how each variant performs relative to each other. You then choose the best-performing model to replace a previously-existing model new version delivers better performance than the previously-existing version.\n",
    "\n",
    "Amazon SageMaker enables you to test multiple models or model versions behind the same endpoint using production variants. Each production variant identifies a machine learning (ML) model and the resources deployed for hosting the model. You can distribute endpoint invocation requests across multiple production variants by providing the traffic distribution for each variant, or you can invoke a specific variant directly for each request.\n",
    "\n",
    "In this notebook we'll:\n",
    "* Evaluate models by invoking specific variants\n",
    "* Gradually release a new model by specifying traffic distribution\n",
    "\n",
    "Reference notebook example: [A/B Testing with Amazon SageMaker](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_endpoints/a_b_testing/a_b_testing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce61ca-dfb0-455f-afb4-9a28fac22b84",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "Let's set up some required imports and basic initial variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96189bf5-9d67-4da7-88bd-9b33aa183225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "sm_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sm_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "sm_client = boto3.client(\"sagemaker\", region)\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "prefix = \"sagemaker/huggingface-pytorch-sentiment-analysis\"\n",
    "time_now = f'{datetime.datetime.now():%Y-%m-%d-%H-%M-%S}'\n",
    "time_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51753a7c-b26e-40d3-be31-ea8f6b3e4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a1d40-d5cb-40c1-8895-386a9bb5e4ae",
   "metadata": {},
   "source": [
    "### Step 1: Deploy the models created in the previous multi-model endpoint notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994e573-1e64-4e39-bb92-e78d9e991575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def production_variant(\n",
    "    model_name,\n",
    "    instance_type=None,\n",
    "    initial_instance_count=None,\n",
    "    variant_name=\"AllTraffic\",\n",
    "    initial_weight=1,\n",
    "    accelerator_type=None,\n",
    "    serverless_inference_config=None,\n",
    "):\n",
    "    \"\"\"Create a production variant description suitable for use in a ``ProductionVariant`` list.\n",
    "    This is also part of a ``CreateEndpointConfig`` request.\n",
    "    Args:\n",
    "        model_name (str): The name of the SageMaker model this production variant references.\n",
    "        instance_type (str): The EC2 instance type for this production variant. For example,\n",
    "            'ml.c4.8xlarge'.\n",
    "        initial_instance_count (int): The initial instance count for this production variant\n",
    "            (default: 1).\n",
    "        variant_name (string): The ``VariantName`` of this production variant\n",
    "            (default: 'AllTraffic').\n",
    "        initial_weight (int): The relative ``InitialVariantWeight`` of this production variant\n",
    "            (default: 1).\n",
    "        accelerator_type (str): Type of Elastic Inference accelerator for this production variant.\n",
    "            For example, 'ml.eia1.medium'.\n",
    "            For more information: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html\n",
    "        serverless_inference_config (dict): Specifies configuration dict related to serverless\n",
    "            endpoint. The dict is converted from sagemaker.model_monitor.ServerlessInferenceConfig\n",
    "            object (default: None)\n",
    "    Returns:\n",
    "        dict[str, str]: An SageMaker ``ProductionVariant`` description\n",
    "    \"\"\"\n",
    "    production_variant_configuration = {\n",
    "        \"ModelName\": model_name,\n",
    "        \"VariantName\": variant_name,\n",
    "        \"InitialVariantWeight\": initial_weight,\n",
    "    }\n",
    "\n",
    "    if accelerator_type:\n",
    "        production_variant_configuration[\"AcceleratorType\"] = accelerator_type\n",
    "\n",
    "    if serverless_inference_config:\n",
    "        production_variant_configuration[\"ServerlessConfig\"] = serverless_inference_config\n",
    "    else:\n",
    "        initial_instance_count = initial_instance_count or 1\n",
    "        production_variant_configuration[\"InitialInstanceCount\"] = initial_instance_count\n",
    "        production_variant_configuration[\"InstanceType\"] = instance_type\n",
    "\n",
    "    return production_variant_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2773a3-754f-4119-bf45-7cb4ba200f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant1 = production_variant(\n",
    "    model_name=roberta_mme_model_name,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    variant_name=\"Variant1\",\n",
    "    initial_weight=1,\n",
    ")\n",
    "variant2 = production_variant(\n",
    "    model_name=distilbert_model_name,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    variant_name=\"Variant2\",\n",
    "    initial_weight=1,\n",
    ")\n",
    "\n",
    "(variant1, variant2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006b375-e844-4d39-b431-205379141d28",
   "metadata": {},
   "source": [
    "#### Deploy\n",
    "Let's go ahead and deploy our two variants to a SageMaker endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b014b-d825-4bd7-92cf-abb15a896cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoint(endpoint_name, config_name, tags=None):\n",
    "    \"\"\"Create an Amazon SageMaker ``Endpoint`` according to the configuration in the request.\n",
    "        Once the ``Endpoint`` is created, client applications can send requests to obtain\n",
    "        inferences. The endpoint configuration is created using the ``CreateEndpointConfig`` API.\n",
    "        Args:\n",
    "            endpoint_name (str): Name of the Amazon SageMaker ``Endpoint`` being created.\n",
    "            config_name (str): Name of the Amazon SageMaker endpoint configuration to deploy.\n",
    "            wait (bool): Whether to wait for the endpoint deployment to complete before returning\n",
    "                (default: True).\n",
    "        Returns:\n",
    "            str: Name of the Amazon SageMaker ``Endpoint`` created.\n",
    "    \"\"\"\n",
    "    print(\"Creating endpoint with name {}\".format(endpoint_name))\n",
    "\n",
    "    tags = tags or []\n",
    "\n",
    "    sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name, EndpointConfigName=config_name, Tags=tags\n",
    "    )\n",
    "    return endpoint_name\n",
    "\n",
    "def endpoint_from_production_variants(\n",
    "    name,\n",
    "    production_variants,\n",
    "    tags=None,\n",
    "    kms_key=None,\n",
    "    data_capture_config_dict=None,\n",
    "    async_inference_config_dict=None,\n",
    "):\n",
    "    \"\"\"Create an SageMaker ``Endpoint`` from a list of production variants.\n",
    "    Args:\n",
    "        name (str): The name of the ``Endpoint`` to create.\n",
    "        production_variants (list[dict[str, str]]): The list of production variants to deploy.\n",
    "        tags (list[dict[str, str]]): A list of key-value pairs for tagging the endpoint\n",
    "            (default: None).\n",
    "        kms_key (str): The KMS key that is used to encrypt the data on the storage volume\n",
    "            attached to the instance hosting the endpoint.\n",
    "        wait (bool): Whether to wait for the endpoint deployment to complete before returning\n",
    "            (default: True).\n",
    "        data_capture_config_dict (dict): Specifies configuration related to Endpoint data\n",
    "            capture for use with Amazon SageMaker Model Monitoring. Default: None.\n",
    "        async_inference_config_dict (dict) : specifies configuration related to async endpoint.\n",
    "            Use this configuration when trying to create async endpoint and make async inference\n",
    "            (default: None)\n",
    "    Returns:\n",
    "        str: The name of the created ``Endpoint``.\n",
    "    \"\"\"\n",
    "    config_options = {\"EndpointConfigName\": name, \"ProductionVariants\": production_variants}\n",
    "    if tags:\n",
    "        config_options[\"Tags\"] = tags\n",
    "    if kms_key:\n",
    "        config_options[\"KmsKeyId\"] = kms_key\n",
    "    if data_capture_config_dict is not None:\n",
    "        config_options[\"DataCaptureConfig\"] = data_capture_config_dict\n",
    "    if async_inference_config_dict is not None:\n",
    "        config_options[\"AsyncInferenceConfig\"] = async_inference_config_dict\n",
    "\n",
    "    print(\"Creating endpoint-config with name {}\".format(name))\n",
    "    sm_client.create_endpoint_config(**config_options)\n",
    "\n",
    "    return create_endpoint(endpoint_name=name, config_name=name, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537189d-4db5-47ec-b415-7e7242e92fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"demo-hf-pytorch-variant-{time_now}\"\n",
    "print(f\"EndpointName={endpoint_name}\")\n",
    "\n",
    "endpoint_from_production_variants(\n",
    "    name=endpoint_name, production_variants=[variant1, variant2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a22d21-5cb1-4526-bf21-b8fe5c5f765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "while describe_endpoint_response[\"EndpointStatus\"] == \"Creating\":\n",
    "    describe_endpoint_response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    print(describe_endpoint_response[\"EndpointStatus\"])\n",
    "    time.sleep(20)\n",
    "\n",
    "describe_endpoint_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc1c36-64d3-4bd0-8cfb-f08f6a4f80d4",
   "metadata": {},
   "source": [
    "## Step 2: Invoke the deployed models\n",
    "\n",
    "You can now send data to this endpoint to get inferences in real time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96fbfa-3823-41a0-ab02-5f70e339e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../sample_payload/test_data.csv\", header=None)\n",
    "json_data = dict({'inputs':test_data.iloc[:,0].to_list()})\n",
    "batch_data = pd.read_csv(\"../sample_payload/batch_data.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8744a-9d1c-4a78-b52e-ddc9bc0f0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = []\n",
    "\n",
    "for i in range(5):\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(json_data),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    predictions.append(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(*predictions, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e8afe-3ad3-4454-9cde-110d645b7a3e",
   "metadata": {},
   "source": [
    "### Invoke a specific variant\n",
    "\n",
    "Now, let’s use the new feature that was released today to invoke a specific variant. For this, we simply use the new parameter to define which specific ProductionVariant we want to invoke. Let us use this to invoke Variant1 for all requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618cbe2-2184-4775-ab85-8e277e0aa542",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(json_data),\n",
    "    ContentType=\"application/json\",\n",
    "    TargetVariant=variant1[\"VariantName\"],\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ca3e9-0b2d-432b-98a1-88fe2c0c166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(json_data),\n",
    "    ContentType=\"application/json\",\n",
    "    TargetVariant=variant2[\"VariantName\"],\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178c6ae-4ed1-4744-9aea-8afba7e94959",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate variant performance\n",
    "\n",
    "### Evaluating Variant 1\n",
    "\n",
    "Using the new targeting feature, let us evaluate the accuracy, precision, recall, F1 score, and ROC/AUC for Variant1:\n",
    "\n",
    "Note that the test data was from [Kaggle financial sentiment analysis dataset](https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74752c-ebc7-4896-9f1b-1b07eec4e61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df_data = pd.read_csv(\"../sample_payload/batch_data.csv\")\n",
    "source_data = df_data.to_json(orient='records')\n",
    "json_lst = json.loads(source_data)\n",
    "json_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a1c3b-3d3e-451c-96a9-3d76beb00866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_with_single_sentence(list_data, endpoint_name, variant_name):\n",
    "    print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "    predictions = []\n",
    "    for payload in list_data:\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=\"application/json\",\n",
    "            Body=json.dumps(payload),\n",
    "            TargetVariant=variant_name,\n",
    "        )\n",
    "        predictions.append(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "        time.sleep(0.5)\n",
    "    print('\\nDone!')\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23abc668-2c11-4d41-bd8b-f8a901ee677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = invoke_with_single_sentence(json_lst, endpoint_name, variant1[\"VariantName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ddfd5-6c2a-4705-a348-adcbfe8ed7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['label','score'])\n",
    "for prediction in predictions1:\n",
    "    tmp_df = pd.DataFrame(json.loads(prediction)[0])\n",
    "    new_row = tmp_df[tmp_df['score']==max(tmp_df['score'])]\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f71370-cd81-497f-9b30-b747c58b3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_map = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}\n",
    "df = df.replace({'label': value_map})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff1f99-b6a4-4de5-9268-d0254e9cbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the labels of our test set; we will use these to evaluate our predictions\n",
    "df_with_labels = pd.read_csv(\"../sample_payload/batch_data_groundtruth.csv\")\n",
    "\n",
    "value_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "df_with_labels = df_with_labels.replace({'sentiment': value_map})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc71175-34ec-4da7-a970-44ba7a6db868",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = df_with_labels.iloc[:, 1]\n",
    "labels = test_labels.to_numpy()\n",
    "preds = df.label.to_numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(preds == labels) / len(labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7da75c-b1bd-4a98-abdb-cb7d93e3534a",
   "metadata": {},
   "source": [
    "### Next, we collect data for Variant2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e2b006-1229-42de-9534-45bcfaabb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = invoke_with_single_sentence(json_lst, endpoint_name, variant2[\"VariantName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24c154-51d0-41dc-9f38-bf97445ae442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=['label','score'])\n",
    "for prediction in predictions2:\n",
    "    tmp_df = pd.DataFrame(json.loads(prediction))\n",
    "    new_row = tmp_df[tmp_df['score']==max(tmp_df['score'])]\n",
    "    df2 = df2.append(new_row, ignore_index=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c5a65-c633-4126-9166-3b849f4c316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_map = {'NEGATIVE': 0, 'POSITIVE': 1}\n",
    "df2 = df2.replace({'label': value_map})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17aa31-729e-47ef-b856-69d3b7313e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df2.label.to_numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(preds == labels) / len(labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847607d-6fdc-45d4-ba0a-54753adb2378",
   "metadata": {},
   "source": [
    "## Step 4: Dialing up our chosen variant in production\n",
    "\n",
    "Now that we have determined Variant1 to be better as compared to Variant2, we will shift more traffic to it. \n",
    "\n",
    "We can continue to use TargetVariant to continue invoking a chosen variant. A simpler approach is to update the weights assigned to each variant using UpdateEndpointWeightsAndCapacities. This changes the traffic distribution to your production variants without requiring updates to your endpoint. \n",
    "\n",
    "Recall our variant weights are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9072b-9a94-491a-b8b5-df7120f5ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    variant[\"VariantName\"]: variant[\"CurrentWeight\"]\n",
    "    for variant in sm_client.describe_endpoint(EndpointName=endpoint_name)[\"ProductionVariants\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78da1b-ecce-421c-9bc8-4d0706a93e01",
   "metadata": {},
   "source": [
    "We'll first write a method to easily invoke our endpoint (a copy of what we had been previously doing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e491817-741f-46f5-8bb7-6420de9585b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint_for_two_minutes():\n",
    "    with open(\"../sample_payload/batch_data.csv\", \"r\") as f:\n",
    "        count=0\n",
    "        for row in f:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = sm_runtime.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    "            )\n",
    "            response[\"Body\"].read().decode(\"utf-8\")\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db343c-fb9d-4820-831f-6c727e546112",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_name, start_time, end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=\"Invocations\",\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "    )\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop(\"Unit\", axis=1)\n",
    "        .rename(columns={\"Sum\": variant_name})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_metrics(start_time=None):\n",
    "    start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "    end_time = datetime.datetime.now()\n",
    "    metrics_variant1 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variant1[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variant2 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variant2[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variants = metrics_variant1.join(metrics_variant2, how=\"outer\")\n",
    "    metrics_variants.plot()\n",
    "    return metrics_variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a2a2d-37e6-4ea6-b42d-f2a34814ed03",
   "metadata": {},
   "source": [
    "We invoke our endpoint for a bit, to show the even split in invocations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32d0bb-1f3a-48ed-9d74-db6cfa29330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_start_time = datetime.datetime.now()\n",
    "invoke_endpoint_for_two_minutes()\n",
    "time.sleep(20)  # give metrics time to catch up\n",
    "plot_endpoint_metrics(invocation_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20419a-8832-4739-80ea-fae0b04afce4",
   "metadata": {},
   "source": [
    "Now let us shift 75% of the traffic to Variant1 by assigning new weights to each variant using UpdateEndpointWeightsAndCapacities. Amazon SageMaker will now send 75% of the inference requests to Variant1 and remaining 25% of requests to Variant2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3415aa-1566-4e1b-adb5-1ef15ff5eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\"DesiredWeight\": 75, \"VariantName\": variant1[\"VariantName\"]},\n",
    "        {\"DesiredWeight\": 25, \"VariantName\": variant2[\"VariantName\"]},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d859e3-e2a9-406b-aa3e-05461b5e0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting for update to complete\")\n",
    "while True:\n",
    "    status = sm_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "    if status in [\"InService\", \"Failed\"]:\n",
    "        print(\"Done\")\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "{\n",
    "    variant[\"VariantName\"]: variant[\"CurrentWeight\"]\n",
    "    for variant in sm_client.describe_endpoint(EndpointName=endpoint_name)[\"ProductionVariants\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965321b-43f6-42dc-8108-e534cbdc249b",
   "metadata": {},
   "source": [
    "Now let's check how that has impacted invocation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2207b5-e0c4-4b32-a2e9-6af422ed4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint_for_two_minutes()\n",
    "time.sleep(20)  # give metrics time to catch up\n",
    "plot_endpoint_metrics(invocation_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc839b-ca65-44d4-8d0d-d8d810e65af4",
   "metadata": {},
   "source": [
    "We can continue to monitor our metrics and when we're satisfied with a variant's performance, we can route 100% of the traffic over the variant. We used UpdateEndpointWeightsAndCapacities to update the traffic assignments for the variants. The weight for Variant1 is set to 0 and the weight for Variant2 is set to 1. Therefore, Amazon SageMaker will send 100% of all inference requests to Variant2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfd003-8954-4542-8fef-74206d60872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\"DesiredWeight\": 1, \"VariantName\": variant1[\"VariantName\"]},\n",
    "        {\"DesiredWeight\": 0, \"VariantName\": variant2[\"VariantName\"]},\n",
    "    ],\n",
    ")\n",
    "print(\"Waiting for update to complete\")\n",
    "while True:\n",
    "    status = sm_client.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "    if status in [\"InService\", \"Failed\"]:\n",
    "        print(\"Done\")\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "{\n",
    "    variant[\"VariantName\"]: variant[\"CurrentWeight\"]\n",
    "    for variant in sm_client.describe_endpoint(EndpointName=endpoint_name)[\"ProductionVariants\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b8ae6-818d-4377-af7c-08a0a1a48acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint_for_two_minutes()\n",
    "time.sleep(20)  # give metrics time to catch up\n",
    "plot_endpoint_metrics(invocation_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bcd5e-771c-48fe-8ba0-c10e7e5f954d",
   "metadata": {},
   "source": [
    "The Amazon CloudWatch metrics for the total invocations for each variant below shows us that all inference requests are being processed by Variant1 and there are no inference requests processed by Variant2.\n",
    "\n",
    "You can now safely update your endpoint and delete Variant2 from your endpoint. You can also continue testing new models in production by adding new variants to your endpoint and following steps 2 - 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4338605-82d7-4274-a8a8-5e815c42f6e1",
   "metadata": {},
   "source": [
    "## Delete the endpoint\n",
    "\n",
    "If you do not plan to use this endpoint further, you should delete the endpoint to avoid incurring additional charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925712f1-6cdc-414b-932d-30d59ba4c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
